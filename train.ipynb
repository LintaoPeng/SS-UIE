{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_ssim\n",
    "from net.model import SS_UIE_model\n",
    "from utils.utils import *\n",
    "from utils.LAB import *\n",
    "from utils.LCH import *\n",
    "from utils.FDL import *\n",
    "import cv2\n",
    "import time as time\n",
    "import datetime\n",
    "import sys\n",
    "from torchvision.utils import save_image\n",
    "import csv\n",
    "import random\n",
    "import torch.utils.data as dataf\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plt/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "dtype = 'float32'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "torch.cuda.set_device(2)\n",
    "torch.set_default_tensor_type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(batches_done):\n",
    "    \"\"\"Saves a generated sample from the validation set\"\"\"\n",
    "\n",
    "    SS_UIE.eval()\n",
    "    i=random.randrange(1,500)\n",
    "    real_A = Variable(x_test[i,:,:,:]).cuda()\n",
    "    real_B = Variable(Y_test[i,:,:,:]).cuda()\n",
    "    real_A=real_A.unsqueeze(0)\n",
    "    real_B=real_B.unsqueeze(0)\n",
    "    fake_B = SS_UIE(real_A)\n",
    "    #print(fake_B.shape)\n",
    "    imgx=fake_B.data\n",
    "    imgy=real_B.data\n",
    "    x=imgx[:,:,:,:]\n",
    "    y=imgy[:,:,:,:]\n",
    "    img_sample = torch.cat((x,y), -2)\n",
    "    save_image(img_sample, \"images/%s/%s.png\" % ('results', batches_done), nrow=5, normalize=True)#要改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([10410, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "training_x=[]\n",
    "path='./data/Train/input/'#要改\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    training_x.append(imgx)   \n",
    "\n",
    "X_train = []\n",
    "for features in training_x:\n",
    "    X_train.append(features)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_train=X_train.astype(dtype)\n",
    "X_train= torch.from_numpy(X_train)\n",
    "X_train=X_train.permute(0,3,1,2)\n",
    "#X_train=X_train.unsqueeze(1)\n",
    "X_train=X_train/255.0\n",
    "print(\"input shape:\",X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([10410, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "training_y=[]\n",
    "path='./data/Train/GT/'#要改\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    training_y.append(imgx)\n",
    "\n",
    "\n",
    "y_train = []\n",
    "for features in training_y:\n",
    "    y_train.append(features)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_train=y_train.astype(dtype)\n",
    "y_train= torch.from_numpy(y_train)\n",
    "y_train=y_train.permute(0,3,1,2)\n",
    "y_train=y_train/255.0\n",
    "print(\"output shape:\",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test input shape: torch.Size([500, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "test_x=[]\n",
    "path='./data/Test-L504/input/'#要改\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    test_x.append(imgx)\n",
    "\n",
    "\n",
    "x_test = []\n",
    "for features in test_x:\n",
    "    x_test.append(features)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "x_test=x_test.astype(dtype)\n",
    "x_test= torch.from_numpy(x_test)\n",
    "x_test=x_test.permute(0,3,1,2)\n",
    "x_test=x_test/255.0\n",
    "print(\"test input shape:\",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test output shape: torch.Size([500, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "test_Y=[]\n",
    "path='./data/Test-L504/GT/'#要改\n",
    "path_list = os.listdir(path)\n",
    "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
    "for item in path_list:\n",
    "    impath=path+item\n",
    "    #print(\"开始处理\"+impath)\n",
    "    imgx= cv2.imread(path+item)\n",
    "    imgx=cv2.resize(imgx,(256,256))\n",
    "    test_Y.append(imgx)\n",
    "\n",
    "\n",
    "Y_test = []\n",
    "for features in test_Y:\n",
    "    Y_test.append(features)\n",
    "\n",
    "Y_test = np.array(Y_test)\n",
    "Y_test=Y_test.astype(dtype)\n",
    "Y_test= torch.from_numpy(Y_test)\n",
    "Y_test=Y_test.permute(0,3,1,2)\n",
    "Y_test=Y_test/255.0\n",
    "print(\"test output shape:\",Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataf.TensorDataset(X_train,y_train)\n",
    "loader = dataf.DataLoader(dataset, batch_size=8, shuffle=True,num_workers=4)\n",
    "SS_UIE = SS_UIE_model(in_channels=3, channels=12, num_memblock=4, num_resblock=4).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plt/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "#net.apply(weights_init_kaiming)\n",
    "MSE= nn.L1Loss(size_average=False).cuda()\n",
    "SSIM = pytorch_ssim.SSIM().cuda()\n",
    "L_lab=lab_Loss().cuda()\n",
    "L_lch=lch_Loss().cuda()\n",
    "FDL_loss = FDL(loss_weight=1.0,alpha=2.0,patch_factor=4,ave_spectrum=True,log_matrix=True,batch_matrix=True).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=0.0001\n",
    "\n",
    "optimizer = torch.optim.Adam(SS_UIE.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "scheduler=optim.lr_scheduler.StepLR(optimizer,step_size=200,gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pretrain model found, training will start from scratch！\n"
     ]
    }
   ],
   "source": [
    "use_pretrain=False\n",
    "if use_pretrain:\n",
    "    # Load pretrained models\n",
    "    start_epoch=0\n",
    "    SS_UIE.load_state_dict(torch.load(\"saved_models/SS_UIE_%d.pth\" % (start_epoch)))\n",
    "    print('successfully loading epoch {} 成功！'.format(start_epoch))\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    print('No pretrain model found, training will start from scratch！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/500] [Batch 210/1302][PSNR: 19.696955] [SSIM: 0.865170][loss: 85.320877][loss_lch: 21.802507][loss_lab: 32.422994][fdl_loss: 6.828656] ETA: 2 days, 7:14:16.39625179"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m output \u001b[38;5;241m=\u001b[39m memnet(Input)\n\u001b[1;32m     35\u001b[0m loss_RGB\u001b[38;5;241m=\u001b[39m MSE(output, GT)\u001b[38;5;241m/\u001b[39m(GT\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m loss_lab \u001b[38;5;241m=\u001b[39m (\u001b[43mL_lab\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m+\u001b[39mL_lab(output, GT)\u001b[38;5;241m+\u001b[39mL_lab(output, GT)\u001b[38;5;241m+\u001b[39mL_lab(output, GT))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4.0\u001b[39m\n\u001b[1;32m     37\u001b[0m loss_lch \u001b[38;5;241m=\u001b[39m (L_lch(output, GT)\u001b[38;5;241m+\u001b[39mL_lch(output, GT)\u001b[38;5;241m+\u001b[39mL_lch(output, GT)\u001b[38;5;241m+\u001b[39mL_lch(output, GT))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4.0\u001b[39m    \n\u001b[1;32m     38\u001b[0m loss_ssim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mSSIM(output,GT)\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mamba/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/data/plt/UIE_based_on_spatial-frequency-self-attention-and-frequency-loss/code/SF-UIE-v3/utils/LAB.py:38\u001b[0m, in \u001b[0;36mlab_Loss.forward\u001b[0;34m(self, img, gt)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,img,gt):\n\u001b[0;32m---> 38\u001b[0m \t    tab\u001b[38;5;241m=\u001b[39m\u001b[43mquantAB\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \t    lab_img\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mclamp(rgb2lab(img),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvmin,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvmax)\n\u001b[1;32m     40\u001b[0m \t    lab_gt\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mclamp(rgb2lab(gt),\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvmin,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvmax)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "f1 = open('psnr.csv','w',encoding='utf-8')#要改\n",
    "csv_writer1 = csv.writer(f1)\n",
    "f2 = open('SSIM.csv','w',encoding='utf-8')#要改\n",
    "csv_writer2 = csv.writer(f2)\n",
    "\n",
    "checkpoint_interval=5\n",
    "epochs=start_epoch\n",
    "n_epochs=500\n",
    "sample_interval=1000\n",
    "\n",
    "# ingnored when opt.mode=='S'\n",
    "psnr_list = [] \n",
    "prev_time = time.time()\n",
    "\n",
    "for epoch in range(epochs,n_epochs):\n",
    "    for i, batch in enumerate(loader):\n",
    "\n",
    "        # Model inputs\n",
    "        Input = Variable(batch[0]).cuda() \n",
    "        GT = Variable(batch[1]).cuda()\n",
    "\n",
    "\n",
    "\n",
    "        # ------------------\n",
    "        #  Train \n",
    "        # ------------------\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # loss\n",
    "        output = SS_UIE(Input)\n",
    "        loss_RGB= MSE(output, GT)/(GT.size()[2]**2)\n",
    "        loss_lab = (L_lab(output, GT)+L_lab(output, GT)+L_lab(output, GT)+L_lab(output, GT))/4.0\n",
    "        loss_lch = (L_lch(output, GT)+L_lch(output, GT)+L_lch(output, GT)+L_lch(output, GT))/4.0    \n",
    "        loss_ssim=1-SSIM(output,GT)\n",
    "        ssim_value = -(loss_ssim.item()-1)\n",
    "        fdl_loss = FDL_loss(output, GT)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        loss_final=loss_ssim*10+loss_RGB*10+loss_lch+loss_lab*0.0001+fdl_loss*5000\n",
    "\n",
    "\n",
    "\n",
    "        loss_final.backward(retain_graph=True)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "\n",
    "        # Determine approximate time left\n",
    "        batches_done = epoch * len(loader) + i\n",
    "        batches_left = n_epochs * len(loader) - batches_done\n",
    "        out_train= torch.clamp(output, 0., 1.) \n",
    "        psnr_train = batch_PSNR(out_train,GT, 1.)\n",
    "        time_left = datetime.timedelta(seconds=batches_left * (time.time() - prev_time))\n",
    "        prev_time = time.time()\n",
    "\n",
    "        # Print log\n",
    "        if batches_done%5==0:\n",
    "            sys.stdout.write(\n",
    "                \"\\r[Epoch %d/%d] [Batch %d/%d][PSNR: %f] [SSIM: %f][loss: %f][loss_lch: %f][loss_lab: %f][fdl_loss: %f] ETA: %s\"\n",
    "                % (\n",
    "                    epoch,\n",
    "                    n_epochs,\n",
    "                    i,\n",
    "                    len(loader),\n",
    "                    psnr_train,\n",
    "                    ssim_value,\n",
    "                    loss_final.item(),\n",
    "                    loss_lch.item(),\n",
    "                    loss_lab.item()*0.0001,\n",
    "                    fdl_loss.item()*5000, \n",
    "                    time_left,\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "        # If at sample interval save image\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_images(batches_done)\n",
    "            csv_writer1.writerow([str(psnr_train)])\n",
    "            csv_writer2.writerow([str(ssim_value)])\n",
    "\n",
    "\n",
    "    scheduler.step()\n",
    "    if checkpoint_interval != -1 and epoch % checkpoint_interval == 0:\n",
    "        # Save model checkpoints\n",
    "        torch.save(SS_UIE.state_dict(), \"saved_models/uie-SS_UIE_%d.pth\" % (epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
